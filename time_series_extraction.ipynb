{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d6f7f0",
   "metadata": {},
   "source": [
    "# Tool for Time-Series Extraction\n",
    "\n",
    "This tool requires a dataset of geotiff images as an input. Minor alterations will be required to code depending on naming conventions and extensions. See comments for details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13146139",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Tool has numerous required dependcies. Ensure all packages are installed before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bce9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta, date\n",
    "from affine import Affine\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For satellite data\n",
    "import rasterio as rs\n",
    "from rasterio.plot import show\n",
    "import rioxarray\n",
    "import osgeo\n",
    "from osgeo import gdal\n",
    "\n",
    "# Use of open_rasterio gives \"DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray.\" \n",
    "# However, rioxarray does not have the transform information necessary to extract coordinates.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e06bc",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80599a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier name that appears in file name; this will change depending on your personal file naming conventions.\n",
    "# Hemisphere glacier is located in. And the desired extraction point as latitude, longitude coordinates.\n",
    "\n",
    "# Jakobshavn Isbrae Glacier in Greenland\n",
    "# glacier, hemisphere, input_lat, input_lon = 'JAK', 'NORTH', 69.1119, -49.485 \n",
    "glacier, hemisphere, input_lat, input_lon = 'JAK', 'NORTH',69.12257, -49.50090\n",
    "\n",
    "\n",
    "# Pine Island Glacier in Antarctica\n",
    "# glacier, hemisphere, input_lat, input_lon = 'PIG', 'SOUTH', -75.3, -99.1 \n",
    "# glacier, hemisphere, input_lat, input_lon = 'PIG', 'SOUTH',-75.2546 , -98.9910\n",
    "\n",
    "# Data naming info ----------> These will also need to be adjusted based on the users filename format.\n",
    "file_extension = '.coffsN_mag_DuFil_yrF.gc.tiff'  \n",
    "date_format = 'yymmdd'\n",
    "date_interval_format = 'yymmdd_yymmdd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec3a21",
   "metadata": {},
   "source": [
    "## Extract all filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4aa7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all filenames and create an array of all path names using glob module. \n",
    "# This will take a while if it is a large dataset. However, once loaded and saved it does not \n",
    "# need to be run again.\n",
    "\n",
    "# This is the path to where your data is saved\n",
    "data_path = \"/Volumes/b0133/ee21lh/data/velocity/CPOM/\"+ glacier + \"/T*/*/*/*.coffsN_mag_DuFil_yrF.gc.tiff\"\n",
    "\n",
    "stack_paths = glob.glob(data_path)\n",
    "\n",
    "np.save(glacier+'_'+str(input_lat)+'_'+str(input_lon)+'_paths', np.array(stack_paths)) # save paths as a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d5164",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0c9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_paths = np.load(glacier+'_'+str(input_lat)+'_'+str(input_lon)+'_paths.npy') # load paths if not already"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d4429",
   "metadata": {},
   "source": [
    "## Convert extraction cooridinates to WG84 \n",
    "\n",
    "polar_convert package contains Python functions for converting polar stereographic coordinates. \n",
    "\n",
    "Adapted from: https://github.com/nsidc/polarstereo-lonlat-convert-py.\n",
    "\n",
    "Original software was developed by the NASA National Snow and Ice Data Center Distributed Active Archive Center. Author: Chris Torrence, September 2019\n",
    "\n",
    "polar_lonlat_to_xy() function was adapted for the northern hemisphere with a central meridian of -45 degrees to create a new function polar_lonlat_north_to_xy()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e78797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polar_convert.constants import SOUTH\n",
    "from polar_convert.constants import NORTH\n",
    "from polar_convert import polar_lonlat_to_xy\n",
    "from polar_convert import polar_lonlat_north_to_xy\n",
    "\n",
    "true_scale_lat = 71  # true-scale latitude in degrees\n",
    "re = 6378.137  # earth radius in km\n",
    "e = 0.08181919 # earth eccentricity\n",
    "\n",
    "# Convert input point to WGS 84 / Polar Stereographic\n",
    "if hemisphere == 'NORTH':\n",
    "    input_point = polar_lonlat_north_to_xy(input_lon, input_lat, true_scale_lat, re, e, hemisphere)\n",
    "else:\n",
    "    input_point = polar_lonlat_to_xy(input_lon, input_lat, true_scale_lat, re, e, hemisphere)\n",
    "\n",
    "input_x,input_y = [input_point[0]*1000,input_point[1]*1000] # convert from km to m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d329fe9",
   "metadata": {},
   "source": [
    "## Extraction Function\n",
    "\n",
    "For a large dataset this will take quite a while to run. But the print output will ensure it is running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f55599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 681/681 [39:29<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "first_date_index = -(len(file_extension)+len(date_interval_format))\n",
    "second_date_index = -(len(file_extension)+len(date_format))\n",
    "\n",
    "# array which data will be put in of form [date1,date2,speed]\n",
    "time_series = np.empty([len(stack_paths),3]) \n",
    "\n",
    "for i in tqdm(np.arange(0,len(stack_paths))):\n",
    "    \n",
    "    # Extracting dates from file names and save to time_series\n",
    "    date1 = stack_paths[i][first_date_index:first_date_index+len(date_format)]\n",
    "    time_series[i,0] = date1\n",
    "    date2 = stack_paths[i][second_date_index:second_date_index+len(date_format)] \n",
    "    time_series[i,1] = date2\n",
    "    \n",
    "    # Import Geotiff as a DataArray (da) object\n",
    "    da = xr.open_rasterio(stack_paths[i])\n",
    "    \n",
    "    # Extract coordinates\n",
    "    transform = Affine(*da.attrs[\"transform\"])\n",
    "    nx, ny = da.sizes[\"x\"], da.sizes[\"y\"]\n",
    "    x, y = transform * np.meshgrid(np.arange(nx) + 0.5, np.arange(ny) + 0.5)\n",
    "    \n",
    "    # Define pandas dataframe\n",
    "    d = {'x': x.flatten(), 'y': y.flatten(), 'speed (m/yr)': np.array(da).flatten()}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    # Find point in dataset closest to the input latitude and longitude\n",
    "    closest_x = df['x'].sub(input_x).abs().idxmin()\n",
    "    closest_y = df['y'].sub(input_y).abs().idxmin()\n",
    "    extraction_x,extraction_y = df['x'][closest_x], df['y'][closest_y]\n",
    "    \n",
    "    # Extract the speed data at the extraction point and save to time_series\n",
    "    extract_data = df[(df['x']==extraction_x) & (df['y']==extraction_y)]\n",
    "    time_series[i,2]=extract_data['speed (m/yr)'].values[0]\n",
    "    \n",
    "    \n",
    "#     print('Processed ',i+1,' of ',len(stack_paths), 'images')\n",
    "\n",
    "time_series_df = pd.DataFrame(time_series,columns = ['Date1','Date2','speed (m/yr)'])\n",
    "time_series_df.to_csv(glacier+'_'+str(input_lat)+'_'+str(input_lon)+'_speed_time_series.csv',index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7d60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
